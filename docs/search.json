[
  {
    "objectID": "index.html#who-am-i",
    "href": "index.html#who-am-i",
    "title": "",
    "section": "üëã Who am I?",
    "text": "üëã Who am I?"
  },
  {
    "objectID": "index.html#who-are-we",
    "href": "index.html#who-are-we",
    "title": "",
    "section": "üëã Who are we?",
    "text": "üëã Who are we?"
  },
  {
    "objectID": "index.html#who-are-you",
    "href": "index.html#who-are-you",
    "title": "",
    "section": "üëã Who are you?",
    "text": "üëã Who are you?"
  },
  {
    "objectID": "index.html#roadmap",
    "href": "index.html#roadmap",
    "title": "",
    "section": "Roadmap",
    "text": "Roadmap\n\n\nWhat is tidymodels?\nWhy tidymodels?\nApplied example\nResources"
  },
  {
    "objectID": "index.html#byo-venn-diagram",
    "href": "index.html#byo-venn-diagram",
    "title": "",
    "section": "BYO Venn Diagram",
    "text": "BYO Venn Diagram"
  },
  {
    "objectID": "index.html#why-tidymodels-consistency",
    "href": "index.html#why-tidymodels-consistency",
    "title": "",
    "section": "Why tidymodels?‚ÄÅ‚ÄÅConsistency",
    "text": "Why tidymodels?‚ÄÅ‚ÄÅConsistency\n\nHow many different ways can you think of to fit a linear model in R?\n\n\nThe blessing:\n\nMany statistical modeling practitioners implement methods in R\n\nThe curse:\n\nMany statistical modeling practitioners implement methods in R"
  },
  {
    "objectID": "index.html#why-tidymodels-consistency-1",
    "href": "index.html#why-tidymodels-consistency-1",
    "title": "",
    "section": "Why tidymodels?‚ÄÅ‚ÄÅConsistency",
    "text": "Why tidymodels?‚ÄÅ‚ÄÅConsistency\n\n\nmtcars\n#&gt;                      mpg cyl  disp  hp drat    wt  qsec vs am gear\n#&gt; Mazda RX4           21.0   6 160.0 110 3.90 2.620 16.46  0  1    4\n#&gt; Mazda RX4 Wag       21.0   6 160.0 110 3.90 2.875 17.02  0  1    4\n#&gt; Datsun 710          22.8   4 108.0  93 3.85 2.320 18.61  1  1    4\n#&gt; Hornet 4 Drive      21.4   6 258.0 110 3.08 3.215 19.44  1  0    3\n#&gt; Hornet Sportabout   18.7   8 360.0 175 3.15 3.440 17.02  0  0    3\n#&gt; Valiant             18.1   6 225.0 105 2.76 3.460 20.22  1  0    3\n#&gt; Duster 360          14.3   8 360.0 245 3.21 3.570 15.84  0  0    3\n#&gt; Merc 240D           24.4   4 146.7  62 3.69 3.190 20.00  1  0    4\n#&gt; Merc 230            22.8   4 140.8  95 3.92 3.150 22.90  1  0    4\n#&gt; Merc 280            19.2   6 167.6 123 3.92 3.440 18.30  1  0    4\n#&gt; Merc 280C           17.8   6 167.6 123 3.92 3.440 18.90  1  0    4\n#&gt; Merc 450SE          16.4   8 275.8 180 3.07 4.070 17.40  0  0    3\n#&gt; Merc 450SL          17.3   8 275.8 180 3.07 3.730 17.60  0  0    3\n#&gt; Merc 450SLC         15.2   8 275.8 180 3.07 3.780 18.00  0  0    3\n#&gt; Cadillac Fleetwood  10.4   8 472.0 205 2.93 5.250 17.98  0  0    3\n#&gt; Lincoln Continental 10.4   8 460.0 215 3.00 5.424 17.82  0  0    3\n#&gt; Chrysler Imperial   14.7   8 440.0 230 3.23 5.345 17.42  0  0    3\n#&gt; Fiat 128            32.4   4  78.7  66 4.08 2.200 19.47  1  1    4\n#&gt; Honda Civic         30.4   4  75.7  52 4.93 1.615 18.52  1  1    4\n#&gt; Toyota Corolla      33.9   4  71.1  65 4.22 1.835 19.90  1  1    4\n#&gt; Toyota Corona       21.5   4 120.1  97 3.70 2.465 20.01  1  0    3\n#&gt; Dodge Challenger    15.5   8 318.0 150 2.76 3.520 16.87  0  0    3\n#&gt; AMC Javelin         15.2   8 304.0 150 3.15 3.435 17.30  0  0    3\n#&gt; Camaro Z28          13.3   8 350.0 245 3.73 3.840 15.41  0  0    3\n#&gt; Pontiac Firebird    19.2   8 400.0 175 3.08 3.845 17.05  0  0    3\n#&gt; Fiat X1-9           27.3   4  79.0  66 4.08 1.935 18.90  1  1    4\n#&gt; Porsche 914-2       26.0   4 120.3  91 4.43 2.140 16.70  0  1    5\n#&gt; Lotus Europa        30.4   4  95.1 113 3.77 1.513 16.90  1  1    5\n#&gt; Ford Pantera L      15.8   8 351.0 264 4.22 3.170 14.50  0  1    5\n#&gt; Ferrari Dino        19.7   6 145.0 175 3.62 2.770 15.50  0  1    5\n#&gt; Maserati Bora       15.0   8 301.0 335 3.54 3.570 14.60  0  1    5\n#&gt; Volvo 142E          21.4   4 121.0 109 4.11 2.780 18.60  1  1    4\n#&gt;                     carb\n#&gt; Mazda RX4              4\n#&gt; Mazda RX4 Wag          4\n#&gt; Datsun 710             1\n#&gt; Hornet 4 Drive         1\n#&gt; Hornet Sportabout      2\n#&gt; Valiant                1\n#&gt; Duster 360             4\n#&gt; Merc 240D              2\n#&gt; Merc 230               2\n#&gt; Merc 280               4\n#&gt; Merc 280C              4\n#&gt; Merc 450SE             3\n#&gt; Merc 450SL             3\n#&gt; Merc 450SLC            3\n#&gt; Cadillac Fleetwood     4\n#&gt; Lincoln Continental    4\n#&gt; Chrysler Imperial      4\n#&gt; Fiat 128               1\n#&gt; Honda Civic            2\n#&gt; Toyota Corolla         1\n#&gt; Toyota Corona          1\n#&gt; Dodge Challenger       2\n#&gt; AMC Javelin            2\n#&gt; Camaro Z28             4\n#&gt; Pontiac Firebird       2\n#&gt; Fiat X1-9              1\n#&gt; Porsche 914-2          2\n#&gt; Lotus Europa           2\n#&gt; Ford Pantera L         4\n#&gt; Ferrari Dino           6\n#&gt; Maserati Bora          8\n#&gt; Volvo 142E             2"
  },
  {
    "objectID": "index.html#why-tidymodels-consistency-2",
    "href": "index.html#why-tidymodels-consistency-2",
    "title": "",
    "section": "Why tidymodels?‚ÄÅ‚ÄÅConsistency",
    "text": "Why tidymodels?‚ÄÅ‚ÄÅConsistency\n\n\nWith lm():\n\nmodel &lt;- \n  lm(mpg ~ ., mtcars)\n\n\nWith tidymodels:\n\nmodel &lt;-\n  linear_reg() %&gt;%\n  set_engine(\"lm\") %&gt;%\n  fit(mpg ~ ., mtcars)"
  },
  {
    "objectID": "index.html#why-tidymodels-consistency-3",
    "href": "index.html#why-tidymodels-consistency-3",
    "title": "",
    "section": "Why tidymodels?‚ÄÅ‚ÄÅConsistency",
    "text": "Why tidymodels?‚ÄÅ‚ÄÅConsistency\n\n\nWith glmnet:\n\nmodel &lt;- \n  glmnet(\n    as.matrix(mtcars[2:11]),\n    mtcars$mpg\n  )\n\n\nWith tidymodels:\n\nmodel &lt;-\n  linear_reg() %&gt;%\n  set_engine(\"glmnet\") %&gt;%\n  fit(mpg ~ ., mtcars)"
  },
  {
    "objectID": "index.html#why-tidymodels-consistency-4",
    "href": "index.html#why-tidymodels-consistency-4",
    "title": "",
    "section": "Why tidymodels?‚ÄÅ‚ÄÅConsistency",
    "text": "Why tidymodels?‚ÄÅ‚ÄÅConsistency\n\n\nWith h2o:\n\nh2o::h2o.init()\nas.h2o(mtcars, \"mtcars\")\n\nmodel &lt;- \n  h2o.glm(\n    x = colnames(mtcars[2:11]), \n    y = \"mpg\",\n    \"mtcars\"\n  )\n\n\nWith tidymodels:\n\nmodel &lt;-\n  linear_reg() %&gt;%\n  set_engine(\"h2o\") %&gt;%\n  fit(mpg ~ ., mtcars)"
  },
  {
    "objectID": "index.html#why-tidymodels-consistency-5",
    "href": "index.html#why-tidymodels-consistency-5",
    "title": "",
    "section": "Why tidymodels?‚ÄÅ‚ÄÅConsistency",
    "text": "Why tidymodels?‚ÄÅ‚ÄÅConsistency"
  },
  {
    "objectID": "index.html#why-tidymodels-safety1",
    "href": "index.html#why-tidymodels-safety1",
    "title": "",
    "section": "Why tidymodels?‚ÄÅ‚ÄÅSafety1",
    "text": "Why tidymodels?‚ÄÅ‚ÄÅSafety1\n10.1016/j.patter.2023.100804, 10.1097/01.psy.0000127692.23278.a9, 10.1609/aaai.v32i1.11694"
  },
  {
    "objectID": "index.html#why-tidymodels-safety2",
    "href": "index.html#why-tidymodels-safety2",
    "title": "",
    "section": "Why tidymodels?‚ÄÅ‚ÄÅSafety1",
    "text": "Why tidymodels?‚ÄÅ‚ÄÅSafety1\n\nA 2023 review found data leakage to be ‚Äúa widespread failure mode in machine-learning (ML)-based science.‚Äù\n\n\n\nOverfitting leads to analysts believing models are more performant than they actually are.\n\n\n\n\nImplementations of the same machine learning model give differing results, resulting in irreproducibility of modeling results.\n\n\n10.1016/j.patter.2023.100804, 10.1097/01.psy.0000127692.23278.a9, 10.1609/aaai.v32i1.11694"
  },
  {
    "objectID": "index.html#why-tidymodels-safety",
    "href": "index.html#why-tidymodels-safety",
    "title": "",
    "section": "Why tidymodels?‚ÄÅ‚ÄÅSafety",
    "text": "Why tidymodels?‚ÄÅ‚ÄÅSafety"
  },
  {
    "objectID": "index.html#why-tidymodels-extensibility",
    "href": "index.html#why-tidymodels-extensibility",
    "title": "",
    "section": "Why tidymodels?‚ÄÅ‚ÄÅExtensibility",
    "text": "Why tidymodels?‚ÄÅ‚ÄÅExtensibility\n\nCan‚Äôt find the technique you need?"
  },
  {
    "objectID": "index.html#why-tidymodels-deployability",
    "href": "index.html#why-tidymodels-deployability",
    "title": "",
    "section": "Why tidymodels?‚ÄÅDeployability",
    "text": "Why tidymodels?‚ÄÅDeployability\n\nTightly integrated with Posit Workbench and Connect\n\n\n\nWorkbench: scalable, on-demand computational resources\nConnect: share work with collaborators and practitioners"
  },
  {
    "objectID": "index.html#resources",
    "href": "index.html#resources",
    "title": "",
    "section": "Resources",
    "text": "Resources\n\n\n\ntidyverse: r4ds.hadley.nz"
  },
  {
    "objectID": "index.html#resources-1",
    "href": "index.html#resources-1",
    "title": "",
    "section": "Resources",
    "text": "Resources\n\n\n\ntidyverse: r4ds.hadley.nz\ntidymodels: tmwr.org"
  },
  {
    "objectID": "index.html#resources-2",
    "href": "index.html#resources-2",
    "title": "",
    "section": "Resources",
    "text": "Resources\n\n\n\ntidyverse: r4ds.hadley.nz\ntidymodels: tmwr.org\nPosit Team: posit.co/team"
  },
  {
    "objectID": "index.html#resources-3",
    "href": "index.html#resources-3",
    "title": "",
    "section": "Resources",
    "text": "Resources\n\ntidyverse: r4ds.hadley.nz\ntidymodels: tmwr.org\nPosit Team: posit.co/team\nSlides and source code:\n\n\ngithub.com/simonpcouch/tidymodels-uw-2023\n\n\nThank you!\n\n\ngithub.com/simonpcouch/tidymodels-uw-2023"
  },
  {
    "objectID": "example/index.html",
    "href": "example/index.html",
    "title": "Modeling flight delays out of Madison, WI",
    "section": "",
    "text": "I‚Äôve collected some data on all of the outbound flights from Madison, Wisconsin in 2022. In this notebook, we‚Äôll use predictors based on the weather, plane, airline, and flight duration to predict whether a flight will be delayed or not. To do so, we will split up the source data, try out many models‚Äîfrom a logistic regression to a boosted tree to a neural network‚Äîon the training data, and then finetune the most performant model to generate our final model fit. We can then assess the predictive performance of the final model fit on the test set and prepare the model to be deployed.\nIf this is your first time seeing the tidyverse and tidymodels, this notebook will be a wild ride.ü§™ Note that most functions in the code chunks are hyperlinks to function documentation, like this one logistic_reg(). For more on the bigger picture,"
  },
  {
    "objectID": "example/index.html#setup",
    "href": "example/index.html#setup",
    "title": "Modeling flight delays out of Madison, WI",
    "section": "Setup",
    "text": "Setup\nFirst, loading the tidyverse and tidymodels, along with a few additional tidymodels extension packages:\n\n# for data analysis:\nlibrary(tidyverse)\n\n# for modeling:\nlibrary(tidymodels)\nlibrary(finetune)\nlibrary(bonsai)\nlibrary(baguette)\n\nThe finetune package will give us additional tuning functionality, while the bonsai and baguette package provide support for additional model types.\ntidymodels supports a number of R frameworks for parallel computing:\n\n# loading needed packages:\nlibrary(doMC)\nlibrary(parallelly)\n\n# check out how many cores we have:\navailableCores()\n\nsystem \n    10 \n\n# register those cores so that tidymodels can see them:\nregisterDoMC(cores = max(1, availableCores() - 1))\n\nWith a multi-core setup registered, tidymodels will now make use of all of the cores on my computer for expensive computations."
  },
  {
    "objectID": "example/index.html#data-import",
    "href": "example/index.html#data-import",
    "title": "Modeling flight delays out of Madison, WI",
    "section": "Data Import",
    "text": "Data Import\nWe‚Äôll make use of a dataset, msnflights22, containing data on all outbound flights from Madison, Wisconsin in 2022.\n\nload(\"data/msnflights22.rda\")\n\nmsnflights22\n\n# A tibble: 10,754 √ó 14\n   delayed airline     flight origin destination date        hour plane distance\n   &lt;fct&gt;   &lt;chr&gt;       &lt;fct&gt;  &lt;fct&gt;  &lt;fct&gt;       &lt;date&gt;     &lt;dbl&gt; &lt;fct&gt;    &lt;dbl&gt;\n 1 No      Endeavor A‚Ä¶ 51     MSN    ATL         2022-01-01     5 N901‚Ä¶      707\n 2 No      PSA Airlin‚Ä¶ 59     MSN    CLT         2022-01-01     6 N570‚Ä¶      708\n 3 No      Envoy Air   27     MSN    MIA         2022-01-01     6 N280‚Ä¶     1300\n 4 No      American A‚Ä¶ 3      MSN    PHX         2022-01-01     6 N662‚Ä¶     1396\n 5 Yes     American A‚Ä¶ 16     MSN    DFW         2022-01-01     7 N826‚Ä¶      821\n 6 No      SkyWest Ai‚Ä¶ 26     MSN    MSP         2022-01-01     7 N282‚Ä¶      228\n 7 No      United Air‚Ä¶ 1      MSN    EWR         2022-01-01     7 &lt;NA&gt;       799\n 8 No      United Air‚Ä¶ 6      MSN    DEN         2022-01-01     8 N830‚Ä¶      826\n 9 No      Republic A‚Ä¶ 29     MSN    ORD         2022-01-01     8 N654‚Ä¶      109\n10 No      Endeavor A‚Ä¶ 62     MSN    DTW         2022-01-01     9 N582‚Ä¶      311\n# ‚Ñπ 10,744 more rows\n# ‚Ñπ 5 more variables: duration &lt;dbl&gt;, wind_speed &lt;dbl&gt;, precip &lt;dbl&gt;,\n#   visibility &lt;dbl&gt;, plane_year &lt;int&gt;\n\n\n\n\n\n\n\n\nNote\n\n\n\nYou can make your own flights data using the anyflights package! The query_data.R file contains the code used to generate this dataset.\n\n\nWe‚Äôd like to model delayed, a binary outcome variable giving whether a given flight was delayed by 10 or more minutes.\n\n# summarize counts of the outcome variable\nmsnflights22 %&gt;%\n  count(delayed)\n\n# A tibble: 2 √ó 2\n  delayed     n\n  &lt;fct&gt;   &lt;int&gt;\n1 Yes      1825\n2 No       8929\n\n\nPredicting flight delays seems quite difficult given the data we have access to. For example, plotting whether a flight is delayed based on precipitation:\n\n# plot 2 predictors, colored by the outcome\nmsnflights22 %&gt;%\n  filter(precip != 0) %&gt;%\n  ggplot() +\n  aes(x = wind_speed, y = precip, color = delayed) +\n  geom_jitter()\n\n\n\n\nA machine learning may be able to get some traction here, though."
  },
  {
    "objectID": "example/index.html#splitting-up-data",
    "href": "example/index.html#splitting-up-data",
    "title": "Modeling flight delays out of Madison, WI",
    "section": "Splitting up data",
    "text": "Splitting up data\nWe split data into training and testing sets so that, once we‚Äôve trained our final model, we can get an honest assessment of the model‚Äôs performance. Since this data is a time series, we‚Äôll allot the first ~10 months to training and the remainder to testing:\n\n# set the seed for random number generation\nset.seed(1)\n\n# split the flights data into training [jan - oct] and testing  [nov - dec]\nflights_split &lt;- initial_time_split(msnflights22, prop = 5/6)\nflights_train &lt;- training(flights_split)\nflights_test &lt;- testing(flights_split)\n\nThen, we‚Äôll resample the training data using a sliding period.\n\n\n\n\n\n\nNote\n\n\n\nA sliding period is a cross-fold validation technique that takes times into account. The tidymodels packages support more basic resampling schemes like bootstrapping and v-fold cross-validation as well‚Äîsee the rsample package‚Äôs website.\n\n\nWe create 8 folds, where in each fold the analysis set is a 2-month sample of data and the assessment set is the single month following.\n\nset.seed(1)\nflights_folds &lt;- \n  sliding_period(\n    flights_train, \n    index = date, \n    \"month\", \n    lookback = 1, \n    assess_stop = 1\n  )\n\nflights_folds\n\n# Sliding period resampling \n# A tibble: 8 √ó 2\n  splits             id    \n  &lt;list&gt;             &lt;chr&gt; \n1 &lt;split [1783/988]&gt; Slice1\n2 &lt;split [1833/819]&gt; Slice2\n3 &lt;split [1807/930]&gt; Slice3\n4 &lt;split [1749/901]&gt; Slice4\n5 &lt;split [1831/906]&gt; Slice5\n6 &lt;split [1807/920]&gt; Slice6\n7 &lt;split [1826/888]&gt; Slice7\n8 &lt;split [1808/826]&gt; Slice8\n\n\nFor example, in the second split,\n\n# training: february, march, april\ntraining(flights_folds$splits[[2]]) %&gt;% pull(date) %&gt;% month() %&gt;% unique()\n\n[1] 2 3\n\n# testing: may\ntesting(flights_folds$splits[[2]])  %&gt;% pull(date) %&gt;% month() %&gt;% unique()\n\n[1] 4\n\n\n\n\n\n\n\n\nNote\n\n\n\nWhat months will be in the training and testing sets in the third fold?"
  },
  {
    "objectID": "example/index.html#defining-our-modeling-strategies",
    "href": "example/index.html#defining-our-modeling-strategies",
    "title": "Modeling flight delays out of Madison, WI",
    "section": "Defining our modeling strategies",
    "text": "Defining our modeling strategies\nOur basic strategy is to first try out a bunch of different modeling approaches, and once we have an initial sense for how they perform, delve further into the one that looks the most promising.\nWe first define a few recipes, which specify how to process the inputted data in such a way that machine learning models will know how to work with predictors:\n\nrecipe_basic &lt;-\n  recipe(delayed ~ ., flights_train) %&gt;%\n  step_nzv(all_predictors())\n\nrecipe_normalize &lt;-\n  recipe_basic %&gt;%\n  step_YeoJohnson(all_double_predictors()) %&gt;%\n  step_normalize(all_double_predictors())\n\nrecipe_pca &lt;- \n  recipe_normalize %&gt;%\n  step_impute_median(all_numeric_predictors()) %&gt;%\n  step_impute_mode(all_nominal_predictors()) %&gt;%\n  step_pca(all_numeric_predictors(), num_comp = tune())\n\nThese recipes vary in complexity, from basic checks on the input data to advanced feature engineering techniques like principal component analysis.\nWe also define several model specifications. tidymodels comes with support for all sorts of machine learning algorithms, from neural networks to LightGBM boosted trees to plain old logistic regression:\n\nspec_lr &lt;-\n  logistic_reg() %&gt;%\n  set_mode(\"classification\")\n\nspec_bm &lt;- \n  bag_mars(num_terms = tune(), prod_degree = tune()) %&gt;%\n  set_engine(\"earth\") %&gt;% \n  set_mode(\"classification\")\n\nspec_bt &lt;- \n  bag_tree(cost_complexity = tune(), tree_depth = tune(), min_n = tune()) %&gt;%\n  set_engine(\"rpart\") %&gt;%\n  set_mode(\"classification\")\n\nspec_nn &lt;- \n  mlp(hidden_units = tune(), penalty = tune(), epochs = tune()) %&gt;%\n  set_engine(\"nnet\", MaxNWts = 15000) %&gt;%\n  set_mode(\"classification\")\n\nspec_svm &lt;- \n  svm_rbf(cost = tune(), rbf_sigma = tune(), margin = tune()) %&gt;%\n  set_mode(\"classification\")\n\nspec_lgb &lt;-\n  boost_tree(trees = tune(), min_n = tune(), tree_depth = tune(),\n             learn_rate = tune(), stop_iter = 10) %&gt;%\n  set_engine(\"lightgbm\") %&gt;%\n  set_mode(\"classification\")\n\nNote how similar the code for each of these model specifications looks! tidymodels takes care of the ‚Äútranslation‚Äù from our unified syntax to the code that these algorithms expect.\nIf typing all of these out seems cumbersome to you, or you‚Äôre not sure how to define a model specification that makes sense for your data, the usemodels RStudio addin may help!"
  },
  {
    "objectID": "example/index.html#evaluating-models-round-1",
    "href": "example/index.html#evaluating-models-round-1",
    "title": "Modeling flight delays out of Madison, WI",
    "section": "Evaluating models: round 1",
    "text": "Evaluating models: round 1\nWe‚Äôll pair machine learning models with the recipes that make the most sense for them using workflow sets:\n\nwf_set &lt;-\n  # pair the basic recipe with a boosted tree and logistic regression\n  workflow_set(\n    preproc = list(basic = recipe_basic),\n    models = list(boost_tree = spec_lgb, logistic_reg = spec_lr)\n  ) %&gt;%\n  # pair the recipe that centers and scales input variables\n  # with the bagged models, support vector machine, and neural network\n  bind_rows(\n    workflow_set(\n      preproc = list(normalize = recipe_normalize),\n      models = list(\n        bag_tree = spec_bt,\n        bag_mars = spec_bm,\n        svm_rbf = spec_svm,\n        mlp = spec_nn\n      )\n    )\n  ) %&gt;%\n  # pair those same models with a more involved, principal component\n  # analysis preprocessor\n  bind_rows(\n    workflow_set(\n      preproc = list(pca = recipe_pca),\n      models = list(\n        bag_tree = spec_bt,\n        bag_mars = spec_bm,\n        svm_rbf = spec_svm,\n        mlp = spec_nn\n      )\n    )\n  )\n\nwf_set\n\n# A workflow set/tibble: 10 √ó 4\n   wflow_id           info             option    result    \n   &lt;chr&gt;              &lt;list&gt;           &lt;list&gt;    &lt;list&gt;    \n 1 basic_boost_tree   &lt;tibble [1 √ó 4]&gt; &lt;opts[0]&gt; &lt;list [0]&gt;\n 2 basic_logistic_reg &lt;tibble [1 √ó 4]&gt; &lt;opts[0]&gt; &lt;list [0]&gt;\n 3 normalize_bag_tree &lt;tibble [1 √ó 4]&gt; &lt;opts[0]&gt; &lt;list [0]&gt;\n 4 normalize_bag_mars &lt;tibble [1 √ó 4]&gt; &lt;opts[0]&gt; &lt;list [0]&gt;\n 5 normalize_svm_rbf  &lt;tibble [1 √ó 4]&gt; &lt;opts[0]&gt; &lt;list [0]&gt;\n 6 normalize_mlp      &lt;tibble [1 √ó 4]&gt; &lt;opts[0]&gt; &lt;list [0]&gt;\n 7 pca_bag_tree       &lt;tibble [1 √ó 4]&gt; &lt;opts[0]&gt; &lt;list [0]&gt;\n 8 pca_bag_mars       &lt;tibble [1 √ó 4]&gt; &lt;opts[0]&gt; &lt;list [0]&gt;\n 9 pca_svm_rbf        &lt;tibble [1 √ó 4]&gt; &lt;opts[0]&gt; &lt;list [0]&gt;\n10 pca_mlp            &lt;tibble [1 √ó 4]&gt; &lt;opts[0]&gt; &lt;list [0]&gt;\n\n\nNow that we‚Äôve defined each of our modeling configurations, we‚Äôll fit them to the resamples we defined earlier. Here, tune_grid() is applied to each workflow in the workflow set, testing out a set of tuning parameter values for each workflow and assessing the resulting fit.\n\nwf_set_fit &lt;-\n  workflow_map(\n    wf_set, \n    fn = \"tune_grid\", \n    verbose = TRUE, \n    seed = 1,\n    resamples = flights_folds,\n    control = control_grid(parallel_over = \"everything\")\n  )\n\n\n\n\n\n\n\nNote\n\n\n\nworkflow_map() is calling tune_grid() on each modeling workflow we‚Äôve created. You can read more about tune_grid() here.\n\n\nCollecting the information on performance from the resulting object:\n\n# first look at metrics:\nmetrics_wf_set &lt;- collect_metrics(wf_set_fit)\n\nTaking a look at how these models did:\n\n# extract the top roc_auc values\nmetrics_wf_set %&gt;%\n  filter(.metric == \"roc_auc\") %&gt;%\n  arrange(desc(mean)) %&gt;%\n  select(wflow_id, mean, n)\n\n# A tibble: 34 √ó 3\n   wflow_id            mean     n\n   &lt;chr&gt;              &lt;dbl&gt; &lt;int&gt;\n 1 normalize_bag_mars 0.615     8\n 2 normalize_bag_mars 0.613     8\n 3 normalize_bag_mars 0.606     8\n 4 normalize_bag_mars 0.603     8\n 5 normalize_bag_mars 0.598     8\n 6 normalize_mlp      0.562     8\n 7 basic_boost_tree   0.560     8\n 8 basic_boost_tree   0.559     8\n 9 basic_boost_tree   0.557     8\n10 basic_boost_tree   0.556     8\n# ‚Ñπ 24 more rows"
  },
  {
    "objectID": "example/index.html#evaluating-models-round-2",
    "href": "example/index.html#evaluating-models-round-2",
    "title": "Modeling flight delays out of Madison, WI",
    "section": "Evaluating models: round 2",
    "text": "Evaluating models: round 2\nIt looks like a bagged MARS model with centered and scaled predictors was considerably more performant than the other proposed models. Let‚Äôs work with those MARS results and see if we can make any further improvements to performance:\n\nmars_res &lt;- extract_workflow_set_result(wf_set_fit, \"normalize_bag_mars\")\n\nmars_wflow &lt;-\n  workflow() %&gt;%\n  add_recipe(recipe_normalize) %&gt;%\n  add_model(spec_bm)\n\nmars_sim_anneal_fit &lt;-\n  tune_sim_anneal(\n    object = mars_wflow,\n    resamples = flights_folds,\n    iter = 10,\n    initial = mars_res,\n    control = control_sim_anneal(verbose = TRUE, parallel_over = \"everything\")\n  )\n\nLooks like we did make a small improvement:\n\ncollect_metrics(mars_sim_anneal_fit) %&gt;%\n  filter(.metric == \"roc_auc\") %&gt;%\n  arrange(desc(mean))\n\n\n\n# A tibble: 10 √ó 8\n   num_terms prod_degree .metric .estimator .config  mean     n std_err\n       &lt;int&gt;       &lt;int&gt; &lt;chr&gt;   &lt;chr&gt;      &lt;chr&gt;   &lt;dbl&gt; &lt;int&gt;   &lt;dbl&gt;\n 1         4           2 roc_auc binary     Iter1   0.619     8  0.0191\n 2         3           2 roc_auc binary     Iter6   0.612     8  0.0249\n 3         5           2 roc_auc binary     Iter8   0.610     8  0.0185\n 4         4           1 roc_auc binary     Iter9   0.606     8  0.0154\n 5         3           2 roc_auc binary     Iter4   0.605     8  0.0211\n 6         4           1 roc_auc binary     Iter7   0.595     8  0.0205\n 7         3           2 roc_auc binary     Iter10  0.594     8  0.0192\n 8         3           1 roc_auc binary     Iter2   0.591     8  0.0248\n 9         2           1 roc_auc binary     Iter5   0.559     8  0.0183\n10         2           2 roc_auc binary     Iter3   0.555     8  0.0175\n\n\nWe can now train the model with the most optimal performance in cross-validation on the entire training set."
  },
  {
    "objectID": "example/index.html#the-final-model-fit",
    "href": "example/index.html#the-final-model-fit",
    "title": "Modeling flight delays out of Madison, WI",
    "section": "The final model fit",
    "text": "The final model fit\nThe last_fit() function will take care of fitting the most performant model specification to the whole training dataset and evaluating it‚Äôs performance with the test set:\n\nmars_final_fit &lt;-\n  mars_sim_anneal_fit %&gt;%\n  # extract the best hyperparameter configuration\n  select_best(\"roc_auc\") %&gt;%\n  # attach it to the general workflow\n  finalize_workflow(mars_wflow, .) %&gt;%\n  # evaluate the final workflow on the train/test split\n  last_fit(flights_split)\n\nmars_final_fit\n\nThe test set roc_auc() for this model was 0.625. The final fitted workflow can be extracted from mars_final_fit and is ready to predict on new data:\n\nfinal_fit &lt;- extract_workflow(mars_final_fit)"
  },
  {
    "objectID": "example/index.html#deploying-to-connect",
    "href": "example/index.html#deploying-to-connect",
    "title": "Modeling flight delays out of Madison, WI",
    "section": "Deploying to Connect",
    "text": "Deploying to Connect\nFrom here, all we‚Äôd need to do to deploy our fitted model is pass it off to vetiver for deployment to Posit Connect:\n\nfinal_fit_vetiver &lt;- vetiver_model(final_fit, \"simon.couch/flights\")\n\nboard &lt;- board_connect()\n\nvetiver_pin_write(board, final_fit_vetiver)\n\nvetiver_deploy_rsconnect(board, \"simon.couch/flights\")"
  }
]